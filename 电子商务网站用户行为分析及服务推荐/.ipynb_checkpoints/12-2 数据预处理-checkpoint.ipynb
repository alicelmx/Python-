{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "中间类型网页       2036\n",
       "非中间类型网页    835414\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除规则1：统计中间类型网页（带midques_关键字）\n",
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "def count_mid(i):\n",
    "    j = i[['fullURL']].copy()\n",
    "    j['type'] = '非中间类型网页'\n",
    "    j['type'][j['fullURL'].str.contains('midques_')] = '中间类型网页'\n",
    "    \n",
    "    return j['type'].value_counts()\n",
    "\n",
    "counts1 = [count_mid(i) for i in raw_data]\n",
    "counts1 = pd.concat(counts1).groupby(level=0).sum()\n",
    "counts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "无.html点击行为的用户记录    164429\n",
       "有html页面            673021\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除规则2：主网址去掉无.html点击行为的用户记录\n",
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "def count_html(i):\n",
    "    j = i[['fullURL']].copy()\n",
    "    j['type'] = '有html页面'\n",
    "    j['type'][j['fullURL'].str.contains('\\.html')==False] = '无.html点击行为的用户记录'\n",
    "    \n",
    "    return j['type'].value_counts()\n",
    "\n",
    "counts2 = [count_html(i) for i in raw_data]\n",
    "counts2 = pd.concat(counts2).groupby(level=0).sum()\n",
    "counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "其他            767758\n",
       "咨询发布成功          5220\n",
       "快搜免费发布法律咨询     11604\n",
       "快车-律师助手        52868\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除规则3：主网址是律师的浏览信息网页（快车-律师助手）、咨询发布成功、快搜免费发布法律\n",
    "# 规则3 被规则2 包含\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "def count_others(i): \n",
    "    j = i[['pageTitle']].copy()\n",
    "    j['type'] = u'其他'   \n",
    "    j['pageTitle'].fillna(u'空',inplace=True)\n",
    "    j['type'][j['pageTitle'].str.contains(u'快车-律师助手')]= u'快车-律师助手'\n",
    "    j['type'][j['pageTitle'].str.contains(u'咨询发布成功')]= u'咨询发布成功'\n",
    "    j['type'][(j['pageTitle'].str.contains(u'免费发布法律咨询')) | (j['pageTitle'].str.contains(u'法律快搜'))] = u'快搜免费发布法律咨询'\n",
    "    \n",
    "    return j['type'].value_counts()\n",
    "\n",
    "counts3 = [count_others(i) for i in raw_data]\n",
    "counts3 = pd.concat(counts3).groupby(level=0).sum()\n",
    "counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "主网址不包含关键字       101\n",
       "主网址包含关键字     837349\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除规则4: 去掉网址中问号后面的部分，截取问号前面的部分;去掉主网址不包含关键字\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "def count_key(i): \n",
    "    j = i[['fullURL']].copy()\n",
    "    j['fullURL'] = j['fullURL'].str.replace('\\?.*','')\n",
    "    j['type'] = '主网址不包含关键字'   \n",
    "    j['type'][j['fullURL'].str.contains('lawtime')]= '主网址包含关键字'\n",
    "    \n",
    "    return j['type'].value_counts()\n",
    "\n",
    "counts4 = [count_key(i) for i in raw_data]\n",
    "counts4 = pd.concat(counts4).groupby(level=0).sum()\n",
    "counts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837450, 3)\n",
      "(801971, 3)\n"
     ]
    }
   ],
   "source": [
    "# 删除规则5: 重复数据去除\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "counts5 = [i[['fullURL','realIP','timestamp_format']] for i in raw_data]\n",
    "counts5 = pd.concat(counts5)\n",
    "counts5_1 = counts5.drop_duplicates()\n",
    "print(counts5.shape)\n",
    "print(counts5_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始删除\n",
    "raw_data = pd.read_sql('all_gzdata',engine,chunksize=10000)\n",
    "\n",
    "for block in raw_data:\n",
    "    block = block[['realIP', 'fullURL','pageTitle','userID','timestamp_format']].copy()\n",
    "    block['fullURL'] = block['fullURL'].str.replace('\\?.*','')\n",
    "    block = block[(block['fullURL'].str.contains('midques_')==False)&(block['fullURL'].str.contains('\\.html'))&(block['fullURL'].str.contains('lawtime'))]\n",
    "    \n",
    "    block.to_sql('cleaned_1',engine,index = False,if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('cleaned_1',engine,chunksize=10000)\n",
    "\n",
    "for block in raw_data:\n",
    "    block = block[\n",
    "        (block['pageTitle'].str.contains(u'快车-律师助手') == False) & \n",
    "        (block['pageTitle'].str.contains(u'咨询发布成功') == False) &\n",
    "        (block['pageTitle'].str.contains(u'免费发布法律咨询') == False) & \n",
    "        (block['pageTitle'].str.contains(u'法律快搜') == False)\n",
    "         ]\n",
    "    \n",
    "    block.to_sql('cleaned_2',engine,index = False,if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('cleaned_2',engine,chunksize=10000)\n",
    "\n",
    "data = [i for i in raw_data]\n",
    "data = pd.concat(data)\n",
    "data = data.drop_duplicates(['fullURL','userID','timestamp_format'])\n",
    "data.to_sql('cleaned_3',engine,index = False,if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del counts,counts1,counts2,counts3,counts4,counts5,counts5_1,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻页处理\n",
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('cleaned_3',engine,chunksize=10000)\n",
    "\n",
    "def fanye(i):\n",
    "    j = i.copy()\n",
    "    j['fullURL'] = j['fullURL'].str.replace('_\\d{0,2}_\\w{0,2}.html','.html')\n",
    "    j['fullURL'] = j['fullURL'].str.replace('_\\d{0,2}.html','.html')\n",
    "    # 第一次去重\n",
    "    j = j.drop_duplicates(['fullURL','userID'])\n",
    "    \n",
    "    return j\n",
    "data = [fanye(i) for i in raw_data]\n",
    "data = pd.concat(data)\n",
    "# 二次去重\n",
    "data = data.drop_duplicates(['fullURL','userID'])\n",
    "data.to_sql('cleaned_gzdata_1',engine,index = False,if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zixun     393184\n",
       "zhishi    122197\n",
       "else       12783\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 纠正错误分类\n",
    "engine = create_engine('mysql+pymysql://root:lmx1994.ROOT@127.0.0.1:3306/law_site')\n",
    "raw_data = pd.read_sql('cleaned_gzdata_1',engine,chunksize=10000)\n",
    "\n",
    "def two_cats(i):\n",
    "    j = i[['fullURL']].copy()\n",
    "    j['cat'] = 'else'\n",
    "    j['cat'][j['fullURL'].str.contains('(ask)|(askzt)')] = 'zixun'\n",
    "    j['cat'][j['fullURL'].str.contains('(info)|(faguizt)')] = 'zhishi'\n",
    "    \n",
    "    return j\n",
    "    \n",
    "count = [two_cats(i) for i in raw_data]\n",
    "count = pd.concat(count)\n",
    "count_1 = count['cat'].value_counts()\n",
    "count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "infoelsezsk    102032\n",
       "other           20057\n",
       "zsk               108\n",
       "Name: iszsk, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一步 : 手动分析知识类别的网址，得出知识类别下的二级类别有哪些\n",
    "data_1 = count[count['cat']=='zhishi']\n",
    "data_1['iszsk'] = 'other'\n",
    "data_1['iszsk'][data_1['fullURL'].str.contains('info')] = 'infoelsezsk'\n",
    "data_1['iszsk'][data_1['fullURL'].str.contains('zhishiku')] = 'zsk'\n",
    "data_1['iszsk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# 第二步：用正则表达式匹配出网址中二级类别\n",
    "# infoelsezsk\n",
    "pattern_1 = re.compile('/info/(.*?)/',re.S)\n",
    "data_2 = data_1[data_1['iszsk']=='infoelsezsk']\n",
    "\n",
    "def second_cat_1(row):\n",
    "    second_cat = re.findall(pattern_1,row)[0]\n",
    "    return second_cat\n",
    "    \n",
    "data_2['second_cat'] = data_2['fullURL'].apply(second_cat_1)\n",
    "\n",
    "# zsk\n",
    "pattern_2 = re.compile('zhishiku/(.*?)/',re.S)\n",
    "data_3 = data_1[data_1['iszsk']=='zsk']\n",
    "\n",
    "def second_cat_2(row):\n",
    "    second_cat = re.findall(pattern_2,row)[0]\n",
    "    return second_cat\n",
    "    \n",
    "data_3['second_cat'] = data_3['fullURL'].apply(second_cat_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
